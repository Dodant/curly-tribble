{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8651bac5-ea5c-4ffa-9522-716e50578359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_data = pd.read_csv('dataset/price_data_tr.csv')\n",
    "heldout_data = pd.read_csv('dataset/price_data_val.csv')\n",
    "test_data = pd.read_csv('dataset/price_data_ts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c411b0d0-c7f7-4c8a-b166-5128c5d00735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(train_data.shape) #(12968, 21)\n",
    "#print(heldout_data.shape) #(4323, 21)\n",
    "#print(test_data.shape) #(4322, 21)\n",
    "\n",
    "# data.columns\n",
    "# 'id', 'date', \n",
    "# 'price', \n",
    "# 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "# 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a7b41efa-8b62-4735-b398-c9d5ffe06249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최신 연도로 바꾸고 기존 yr_bult, yr_renovated 삭제\n",
    "train_data['yr_max'] = np.maximum(np.array(train_data.yr_built), np.array(train_data.yr_renovated))\n",
    "train_data = train_data.drop(['yr_built','yr_renovated'], axis=1)\n",
    "\n",
    "heldout_data['yr_max'] = np.maximum(np.array(heldout_data.yr_built), np.array(heldout_data.yr_renovated))\n",
    "heldout_data = heldout_data.drop(['yr_built','yr_renovated'], axis=1)\n",
    "\n",
    "test_data['yr_max'] = np.maximum(np.array(test_data.yr_built), np.array(test_data.yr_renovated))\n",
    "test_data = test_data.drop(['yr_built','yr_renovated'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7c530fa7-9bc0-43b5-8df2-622a5e1ed1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop zipcode\n",
    "train_data['zipcode'] = -train_data['zipcode']\n",
    "heldout_data['zipcode'] = -heldout_data['zipcode']\n",
    "test_data['zipcode'] = -test_data['zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9d69f927-0691-4ecf-8cfa-6fac592ea025",
   "metadata": {},
   "outputs": [],
   "source": [
    "e, pi, r2, re = math.e, math.pi, 2 ** 0.5, math.e ** 0.5\n",
    "\n",
    "# bathrooms\n",
    "train_data['bathrooms'] = train_data['bathrooms'].apply(lambda x: x**r2)\n",
    "# sqft_lot\n",
    "train_data['sqft_lot'] = train_data['sqft_lot'].apply(lambda x: x**(1/pi))\n",
    "# floors\n",
    "train_data['floors'] = train_data['floors'].apply(lambda x: x**(1/(pi**pi)))\n",
    "# waterfront\n",
    "train_data['waterfront'] = train_data['waterfront'].apply(lambda x: x**(e**e))\n",
    "# condition\n",
    "train_data['condition'] = train_data['condition'].apply(lambda x: x**(pi**2))\n",
    "# grade\n",
    "train_data['grade'] = train_data['grade'].apply(lambda x: x**(re**re))\n",
    "# sqft_basement\n",
    "train_data['sqft_basement'] = train_data['sqft_basement'].apply(lambda x: x**(r2**r2))\n",
    "# lat\n",
    "train_data['lat'] = train_data['lat'].apply(lambda x: x**(1/(pi**pi)))\n",
    "# sqft_lot15\n",
    "train_data['sqft_lot15'] = train_data['sqft_lot15'].apply(lambda x: x**(1/pi))\n",
    "# yr_max\n",
    "train_data['yr_max'] = train_data['yr_max'].apply(lambda x: x**(e**2))\n",
    "\n",
    "\n",
    "heldout_data['bathrooms'] = heldout_data['bathrooms'].apply(lambda x: x**r2)\n",
    "heldout_data['sqft_lot'] = heldout_data['sqft_lot'].apply(lambda x: x**(1/pi))\n",
    "heldout_data['floors'] = heldout_data['floors'].apply(lambda x: x**(1/(pi**pi)))\n",
    "heldout_data['waterfront'] = heldout_data['waterfront'].apply(lambda x: x**(e**e))\n",
    "heldout_data['condition'] = heldout_data['condition'].apply(lambda x: x**(pi**2))\n",
    "heldout_data['grade'] = heldout_data['grade'].apply(lambda x: x**(re**re))\n",
    "heldout_data['sqft_basement'] = heldout_data['sqft_basement'].apply(lambda x: x**(r2**r2))\n",
    "heldout_data['lat'] = heldout_data['lat'].apply(lambda x: x**(1/(pi**pi)))\n",
    "heldout_data['sqft_lot15'] = heldout_data['sqft_lot15'].apply(lambda x: x**(1/pi))\n",
    "heldout_data['yr_max'] = heldout_data['yr_max'].apply(lambda x: x**(e**2))\n",
    "\n",
    "\n",
    "test_data['bathrooms'] = test_data['bathrooms'].apply(lambda x: x**r2)\n",
    "test_data['sqft_lot'] = test_data['sqft_lot'].apply(lambda x: x**(1/pi))\n",
    "test_data['floors'] = test_data['floors'].apply(lambda x: x**(1/(pi**pi)))\n",
    "test_data['waterfront'] = test_data['waterfront'].apply(lambda x: x**(e**e))\n",
    "test_data['condition'] = test_data['condition'].apply(lambda x: x**(pi**2))\n",
    "test_data['grade'] = test_data['grade'].apply(lambda x: x**(re**re))\n",
    "test_data['sqft_basement'] = test_data['sqft_basement'].apply(lambda x: x**(r2**r2))\n",
    "test_data['lat'] = test_data['lat'].apply(lambda x: x**(1/(pi**pi)))\n",
    "test_data['sqft_lot15'] = test_data['sqft_lot15'].apply(lambda x: x**(1/pi))\n",
    "test_data['yr_max'] = test_data['yr_max'].apply(lambda x: x**(e**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4dad1c57-d226-4a8b-8127-303e1fcac632",
   "metadata": {},
   "outputs": [],
   "source": [
    "nor_train = train_data.iloc[:, 3:].apply(lambda x: (x-x.mean()) / x.std())\n",
    "nor_log_train_price = np.log(train_data.iloc[:, 2:3]).apply(lambda x: (x-x.mean()) / x.std())\n",
    "\n",
    "nor_heldout = heldout_data.iloc[:, 3:].apply(lambda x: (x-x.mean()) / x.std())\n",
    "nor_log_heldout_price = np.log(heldout_data.iloc[:, 2:3]).apply(lambda x: (x-x.mean()) / x.std())\n",
    "\n",
    "nor_test = test_data.iloc[:, 3:].apply(lambda x: (x-x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a841537c-ab2e-41d2-9455-a3e0bd7f0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=True)\n",
    "train_poly = poly_features.fit_transform(nor_train)\n",
    "heldout_poly = poly_features.fit_transform(nor_heldout)\n",
    "test_poly = poly_features.fit_transform(nor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "28e3c6e4-97bd-4e64-979f-40a83fee75d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12968, 17) (12968, 171)\n",
      "<class 'numpy.ndarray'>\n",
      "(4323, 17) (4323, 171)\n",
      "(4322, 17) (4322, 171)\n"
     ]
    }
   ],
   "source": [
    "print(nor_train.shape, train_poly.shape)\n",
    "print(type(train_poly))\n",
    "print(nor_heldout.shape, heldout_poly.shape)\n",
    "print(nor_test.shape, test_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "386bcb9d-b2c2-4ae7-be46-340de3b95756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.04810655020148 0.5220080959315785\n",
      "13.048257499579405 0.5355929705203868\n",
      "13.048144289728448 0.5254218546587482\n"
     ]
    }
   ],
   "source": [
    "train_log_label_mean, train_log_label_std = np.log(train_data['price']).mean(), np.log(train_data['price']).std()\n",
    "print(train_log_label_mean, train_log_label_std)\n",
    "\n",
    "heldout_log_label_mean, heldout_log_label_std = np.log(heldout_data['price']).mean(), np.log(heldout_data['price']).std()\n",
    "print(heldout_log_label_mean, heldout_log_label_std)\n",
    "\n",
    "uni_log_label_mean = np.log(pd.concat((train_data['price'], heldout_data['price']))).mean()\n",
    "uni_log_label_std = np.log(pd.concat((train_data['price'], heldout_data['price']))).std()\n",
    "print(uni_log_label_mean, uni_log_label_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "17e6c4cb-ee51-4fa8-953b-4dca90b6c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = torch.tensor(train_poly, dtype=torch.float32)\n",
    "train_labels = torch.tensor(nor_log_train_price.values.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "heldout_feats = torch.tensor(heldout_poly, dtype=torch.float32)\n",
    "heldout_labels = torch.tensor(nor_log_heldout_price.values.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "test_feat = torch.tensor(test_poly, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "79d41856-cc2e-49ff-b6a1-c5aaa34ad513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12968, 171]) (12968, 171)\n",
      "torch.Size([4323, 171]) (4323, 171)\n",
      "torch.Size([4322, 171]) (4322, 171)\n"
     ]
    }
   ],
   "source": [
    "print(train_feats.shape, train_poly.shape)\n",
    "print(heldout_feats.shape, heldout_poly.shape)\n",
    "print(test_feat.shape, test_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "24e52a1b-6e79-49ff-b7a0-e367a7f329c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, in_features = train_data.shape[0], train_feats.shape[1]\n",
    "\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 16)\n",
    "        self.fc4 = nn.Linear(16, 1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.bn3 = nn.BatchNorm1d(16)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout(self.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5850a4ea-b436-464e-a377-4f52b427b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.1\n",
    "batch_size = 1024\n",
    "epochs = 500\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net = Regressor().to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8717539b-1030-49ba-8e13-c9ec042e3c09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 -- train_rmse: 0.0438, test_rmse: 0.1382\n",
      "epoch: 20 -- train_rmse: 0.0447, test_rmse: 0.1462\n",
      "epoch: 30 -- train_rmse: 0.0452, test_rmse: 0.1603\n",
      "epoch: 40 -- train_rmse: 0.0443, test_rmse: 0.1626\n",
      "epoch: 50 -- train_rmse: 0.0444, test_rmse: 0.1605\n",
      "epoch: 60 -- train_rmse: 0.0419, test_rmse: 0.1522\n",
      "epoch: 70 -- train_rmse: 0.0428, test_rmse: 0.1556\n",
      "epoch: 80 -- train_rmse: 0.0431, test_rmse: 0.1576\n",
      "epoch: 90 -- train_rmse: 0.0423, test_rmse: 0.1512\n",
      "epoch: 100 -- train_rmse: 0.0433, test_rmse: 0.1660\n",
      "epoch: 110 -- train_rmse: 0.0443, test_rmse: 0.1513\n",
      "epoch: 120 -- train_rmse: 0.0423, test_rmse: 0.1617\n",
      "epoch: 130 -- train_rmse: 0.0422, test_rmse: 0.1590\n",
      "epoch: 140 -- train_rmse: 0.0443, test_rmse: 0.1569\n",
      "epoch: 150 -- train_rmse: 0.0425, test_rmse: 0.1740\n",
      "epoch: 160 -- train_rmse: 0.0416, test_rmse: 0.1453\n",
      "epoch: 170 -- train_rmse: 0.0401, test_rmse: 0.1819\n",
      "epoch: 180 -- train_rmse: 0.0408, test_rmse: 0.1490\n",
      "epoch: 190 -- train_rmse: 0.0402, test_rmse: 0.1580\n",
      "epoch: 200 -- train_rmse: 0.0433, test_rmse: 0.1512\n",
      "epoch: 210 -- train_rmse: 0.0417, test_rmse: 0.1860\n",
      "epoch: 220 -- train_rmse: 0.0386, test_rmse: 0.1665\n",
      "epoch: 230 -- train_rmse: 0.0414, test_rmse: 0.1808\n",
      "epoch: 240 -- train_rmse: 0.0434, test_rmse: 0.1628\n",
      "epoch: 250 -- train_rmse: 0.0418, test_rmse: 0.1607\n",
      "epoch: 260 -- train_rmse: 0.0388, test_rmse: 0.1580\n",
      "epoch: 270 -- train_rmse: 0.0400, test_rmse: 0.1549\n",
      "epoch: 280 -- train_rmse: 0.0396, test_rmse: 0.1648\n",
      "epoch: 290 -- train_rmse: 0.0395, test_rmse: 0.1646\n",
      "epoch: 300 -- train_rmse: 0.0386, test_rmse: 0.1783\n",
      "epoch: 310 -- train_rmse: 0.0405, test_rmse: 0.1771\n",
      "epoch: 320 -- train_rmse: 0.0387, test_rmse: 0.1835\n",
      "epoch: 330 -- train_rmse: 0.0416, test_rmse: 0.1573\n",
      "epoch: 340 -- train_rmse: 0.0427, test_rmse: 0.1670\n",
      "epoch: 350 -- train_rmse: 0.0396, test_rmse: 0.1528\n",
      "epoch: 360 -- train_rmse: 0.0395, test_rmse: 0.1670\n",
      "epoch: 370 -- train_rmse: 0.0407, test_rmse: 0.1811\n",
      "epoch: 380 -- train_rmse: 0.0392, test_rmse: 0.1786\n",
      "epoch: 390 -- train_rmse: 0.0395, test_rmse: 0.1757\n",
      "epoch: 400 -- train_rmse: 0.0387, test_rmse: 0.1608\n",
      "epoch: 410 -- train_rmse: 0.0374, test_rmse: 0.1675\n",
      "epoch: 420 -- train_rmse: 0.0384, test_rmse: 0.1867\n",
      "epoch: 430 -- train_rmse: 0.0404, test_rmse: 0.1772\n",
      "epoch: 440 -- train_rmse: 0.0392, test_rmse: 0.1779\n",
      "epoch: 450 -- train_rmse: 0.0388, test_rmse: 0.1964\n",
      "epoch: 460 -- train_rmse: 0.0394, test_rmse: 0.1880\n",
      "epoch: 470 -- train_rmse: 0.0380, test_rmse: 0.1697\n",
      "epoch: 480 -- train_rmse: 0.0377, test_rmse: 0.1684\n",
      "epoch: 490 -- train_rmse: 0.0388, test_rmse: 0.1943\n",
      "epoch: 500 -- train_rmse: 0.0383, test_rmse: 0.1735\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = train_feats.to(device), train_labels.to(device)\n",
    "test_features, test_labels = heldout_feats.to(device), heldout_labels.to(device)\n",
    "\n",
    "dataset = TensorDataset(train_features, train_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "train_ls, test_ls = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    train_rmse = criterion(net(train_features), train_labels).item()\n",
    "    test_rmse = criterion(net(test_features), test_labels).item()\n",
    "    \n",
    "    train_ls.append(train_rmse)\n",
    "    test_ls.append(test_rmse)\n",
    "    \n",
    "    if test_rmse < 0.11:\n",
    "        break\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'epoch: {epoch + 1} -- train_rmse: {train_rmse:.4f}, test_rmse: {test_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b21c41f-7e08-4e93-bb47-619b7ef94379",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = net(train_features).to('cpu').detach().numpy()\n",
    "uni_predicts = np.exp(predicts * train_log_label_std + train_log_label_mean)\n",
    "train_labels_ = np.exp(train_labels.cpu() * train_log_label_std + train_log_label_mean)\n",
    "print(rmse(uni_predicts, np.array(train_labels_)))\n",
    "\n",
    "plt.plot(train_ls, label=\"Train\")\n",
    "plt.plot(test_ls, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'{train_ls[-1]:0.4f}, {test_ls[-1]:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6d1d64d3-187d-4d38-a62d-61c9a178da1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131588.9882797251\n",
      "131751.391756751\n",
      "131443.0004292868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[716624.3 ],\n",
       "       [494908.06],\n",
       "       [209662.36],\n",
       "       ...,\n",
       "       [891221.75],\n",
       "       [541079.44],\n",
       "       [423587.75]], dtype=float32)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains = []\n",
    "helds = []\n",
    "unis = []\n",
    "\n",
    "\n",
    "for i in range(3000):\n",
    "    predicts = net(test_features).to('cpu').detach().numpy()\n",
    "\n",
    "    train_predicts = np.exp(predicts * train_log_label_std + train_log_label_mean)\n",
    "    held_predicts = np.exp(predicts * heldout_log_label_std + heldout_log_label_mean)\n",
    "    uni_predicts = np.exp(predicts * uni_log_label_std + uni_log_label_mean)\n",
    "        \n",
    "    rmse_train = rmse(train_predicts, heldout_data.iloc[:, 2:3].values)\n",
    "    rmse_held = rmse(held_predicts, heldout_data.iloc[:, 2:3].values)\n",
    "    rmse_uni = rmse(uni_predicts, heldout_data.iloc[:, 2:3].values)\n",
    "    \n",
    "    trains.append(rmse_train)\n",
    "    helds.append(rmse_held)\n",
    "    unis.append(rmse_uni)\n",
    "\n",
    "print(np.array(trains).mean())\n",
    "print(np.array(helds).mean())\n",
    "print(np.array(unis).mean())\n",
    "\n",
    "finals = []\n",
    "\n",
    "for i in range(3000):\n",
    "    test_predicts = net(test_feat.to('cuda')).cpu().detach().numpy()\n",
    "    final_predict = np.exp(test_predicts * uni_log_label_std + uni_log_label_mean)\n",
    "    finals.append(final_predict)\n",
    "np.array(finals).mean(axis = 0)\n",
    "\n",
    "# 131588.9882797251\n",
    "# 131751.391756751\n",
    "# 131443.0004292868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0cca6484-e13e-4ce0-bbd5-2d5df3579e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700010085020140926T000000</td>\n",
       "      <td>716624.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>403740028020140923T000000</td>\n",
       "      <td>494908.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142340016020140618T000000</td>\n",
       "      <td>209662.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>776740006020141119T000000</td>\n",
       "      <td>460679.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>946590050020140617T000000</td>\n",
       "      <td>584058.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>733822037020141006T000000</td>\n",
       "      <td>320622.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>681910015020140721T000000</td>\n",
       "      <td>642553.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>082405914020140527T000000</td>\n",
       "      <td>891221.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>051450009020140513T000000</td>\n",
       "      <td>541079.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>770180005020140625T000000</td>\n",
       "      <td>423587.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4322 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id          price\n",
       "0     700010085020140926T000000  716624.312500\n",
       "1     403740028020140923T000000  494908.062500\n",
       "2     142340016020140618T000000  209662.359375\n",
       "3     776740006020141119T000000  460679.562500\n",
       "4     946590050020140617T000000  584058.375000\n",
       "...                         ...            ...\n",
       "4317  733822037020141006T000000  320622.500000\n",
       "4318  681910015020140721T000000  642553.187500\n",
       "4319  082405914020140527T000000  891221.750000\n",
       "4320  051450009020140513T000000  541079.437500\n",
       "4321  770180005020140625T000000  423587.750000\n",
       "\n",
       "[4322 rows x 2 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('dataset/price_data_ts.csv')\n",
    "test_data['price'] = np.array(finals).mean(axis = 0)\n",
    "\n",
    "test_data['id'] = test_data['id'].apply(lambda x : str(x) if len(str(x)) == 10 else '0' + str(x) if len(str(x)) == 9 else '00' + str(x))\n",
    "test_data['id'] = test_data['id'].astype(str) + test_data['date'].astype(str)\n",
    "submission = pd.concat([test_data['id'], test_data['price']], axis=1)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d9e26a46-3270-4a9d-ad73-a65ff33ef6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5b75ba2e-ce29-4142-a3aa-484a6916ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_middle(net, x):\n",
    "    x = net.dropout(net.relu(net.fc1(x)))\n",
    "    x = net.dropout(net.relu(net.fc2(x)))\n",
    "    x = net.dropout(net.relu(net.fc3(x)))\n",
    "    x = net.dropout(net.relu(net.fc4(x)))\n",
    "    x = net.dropout(net.relu(net.fc5(x)))\n",
    "    x = net.fc6(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "583b2c28-e966-4cdc-b285-242455299a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12968, 17])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6ee86ec2-0693-4739-b53d-8c89aa74e1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12968, 64])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_middle(net, train_feats.to('cuda')).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c3077215-04b8-4d21-a853-30a4d1b4d038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12968])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5ccc0f4c-03be-47e2-a302-d586a112f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda() ; train_feats = train_feats.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "81cfadfc-6bea-470a-8c7d-b9ee2f8827a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = RandomForestRegressor()\n",
    "middle_value = extract_middle(net, train_feats)\n",
    "middle_value = middle_value.cpu()\n",
    "middle_value = middle_value.detach().numpy()\n",
    "\n",
    "train_labels_cpu = train_labels.cpu()\n",
    "train_labels_cpu = train_labels_cpu.detach().numpy()\n",
    "\n",
    "model.fit(middle_value, train_labels_cpu.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9e0ecb73-04ce-40e0-b23e-fe3f0b6c27cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균제곱근오차 213644.33121815647\n",
      "평균제곱근오차 213296.51417173128\n",
      "평균제곱근오차 213472.30924589932\n"
     ]
    }
   ],
   "source": [
    "# val_labels_cpu = train_labels.cpu()\n",
    "# val_labels_cpu = train_labels_cpu.detach().numpy()\n",
    "middle_val = extract_middle(net, test_features)\n",
    "middle_val = middle_val.cpu()\n",
    "middle_val = middle_val.detach().numpy()\n",
    "\n",
    "predicts = model.predict(middle_val)\n",
    "train_predicts = np.exp(predicts * train_log_label_std + train_log_label_mean)\n",
    "held_predicts = np.exp(predicts * heldout_log_label_std + heldout_log_label_mean)\n",
    "uni_predicts = np.exp(predicts * uni_log_label_std + uni_log_label_mean)\n",
    "\n",
    "tmse = np.sqrt(mean_squared_error(train_predicts, heldout_data.iloc[:, [2]].values))\n",
    "hmse = np.sqrt(mean_squared_error(held_predicts, heldout_data.iloc[:, [2]].values))\n",
    "umse = np.sqrt(mean_squared_error(uni_predicts, heldout_data.iloc[:, [2]].values))\n",
    "\n",
    "print('평균제곱근오차', tmse)\n",
    "print('평균제곱근오차', hmse)\n",
    "print('평균제곱근오차', umse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a457e92-6257-4b76-9900-94d1c6d91a86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
