{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6f8dd699-4d26-4969-a55e-085314a64064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5e98c14a-2989-4b79-be09-a3d730223844",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "328507c3-05f4-4b0b-bf0d-0226321d2d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 128.8247,  139.8563,  -39.4749,  154.7860,  -36.9190,   34.0017],\n",
       "        [ -82.0351,   98.9571,  148.5400, -123.6163,  146.4595,   31.5363],\n",
       "        [ 124.4893,   22.8201,   81.2487,  -23.7907,  129.8943,   24.9058]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_logit = (torch.rand(3, 6) - 0.5) * random.randint(10, 500)\n",
    "teacher_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "fef746d8-b9cc-4c4f-b4f3-ef3286b5910b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-15.6391,   8.5391, -15.4347,  -3.9286, -13.6063,  22.2229],\n",
       "        [-26.4439, -15.4438,  -9.4596, -20.1426,   3.1618, -33.0872],\n",
       "        [ 30.2542, -28.4572,  25.8629,   5.5750, -10.8776,  20.7013]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_logit = (torch.rand(3, 6) - 0.5) * random.randint(10, 500)\n",
    "student_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "985e2caf-1d98-46c8-b525-ef151526186d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3],\n",
      "        [4],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "labels = [3, # ground truth 일때\n",
    "         4, # ground truth는 아닌 데 topk안에 들 경우\n",
    "         1, # topk안에도 없을 경우\n",
    "        ]\n",
    "\n",
    "labels = torch.tensor(labels, dtype=torch.int64).view(-1,1)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "40f9b24a-5e25-4bbc-8674-f78ff092f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def DistillationLoss(student_logit, teacher_logit, T, threshold):\n",
    "#     new_teacher_logit = teacher_logit + torch.abs(torch.min(teacher_logit, dim=1).values.reshape(-1, 1))\n",
    "#     bar = torch.sort(new_teacher_logit, descending=True).values[:, threshold-1].reshape(-1, 1).repeat(1, teacher_logit.shape[1])\n",
    "#     new_teacher_logit = torch.where(bar <= new_teacher_logit, new_teacher_logit, torch.zeros(1, device=torch.device('cuda')))\n",
    "#     soft_label = F.softmax(new_teacher_logit / T, dim=1)\n",
    "#     soft_prediction = F.log_softmax(student_logit / T, dim=1)\n",
    "#     return F.kl_div(soft_prediction, soft_label)\n",
    "\n",
    "\n",
    "# def FinalLoss(teacher_logit, student_logit, labels, T, alpha, threshold):\n",
    "#     return (1. - alpha) * F.cross_entropy(student_logit, labels) \\\n",
    "#            + (alpha * T * T) * DistillationLoss(student_logit, teacher_logit, T, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b193245f-e18c-45e7-9ce8-59669f264b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "### option 1 - (student_logit, teacher_logit, T, T1, T2, K)\n",
    "# topk 안에 드는 것은 suppress less\n",
    "# topk 안에 안 드는 것은 suppress more\n",
    "# 요약 - topk에 따라 Temperature를 다르게 하자 \n",
    "def option1(student_logit, teacher_logit, T, T1, T2, K):\n",
    "    new_teacher_logit = teacher_logit + torch.abs(torch.min(teacher_logit, dim=1).values.reshape(-1,1))\n",
    "    new_teacher_logit = new_teacher_logit / 2\n",
    "    bar = torch.sort(new_teacher_logit, descending=True).values[:, K-1].reshape(-1, 1).repeat(1, teacher_logit.shape[1])\n",
    "    top = torch.where(bar <= new_teacher_logit, new_teacher_logit, torch.zeros(1))\n",
    "    bot = torch.where(bar > new_teacher_logit, new_teacher_logit, torch.zeros(1))\n",
    "    soft_label = F.softmax((top / T1) + (bot / T2), dim=1)\n",
    "    soft_prediction = F.log_softmax(student_logit / T, dim=1)\n",
    "    return F.kl_div(soft_prediction, soft_label)\n",
    "\n",
    "\n",
    "### option 2 - (student_logit, teacher_logit, labels, T, T1, T2, K)\n",
    "# option 1 + GT가 topk에 들든 안 들든 그만히 놔두자 (Temperature 적용 X)\n",
    "def option2(student_logit, teacher_logit, labels, T, T1, T2, K):\n",
    "    new_teacher_logit = teacher_logit + torch.abs(torch.min(teacher_logit, dim=1).values.reshape(-1,1))\n",
    "    new_teacher_logit = new_teacher_logit / 2\n",
    "    bar = torch.sort(new_teacher_logit, descending=True).values[:, K-1].reshape(-1, 1).repeat(1, teacher_logit.shape[1])\n",
    "    new_teacher_logit_wo_gt = new_teacher_logit.scatter(1, labels, 0)\n",
    "    top = torch.where(bar <= new_teacher_logit_wo_gt, new_teacher_logit_wo_gt, torch.zeros(1))\n",
    "    bot = torch.where(bar > new_teacher_logit_wo_gt, new_teacher_logit_wo_gt, torch.zeros(1))\n",
    "    gt = torch.where(torch.zeros_like(new_teacher_logit).scatter(1, labels, 1) == 1., new_teacher_logit, torch.zeros(1))\n",
    "    top = top / T1\n",
    "    bot = bot / T2\n",
    "    soft_label = F.softmax(top + bot + gt, dim=1)\n",
    "    soft_prediction = F.log_softmax(student_logit / T, dim=1)\n",
    "    return F.kl_div(soft_prediction, soft_label)\n",
    "\n",
    "\n",
    "\n",
    "### option 3 - (student_logit, teacher_logit, T, K)\n",
    "# topk에 안 드는 것은 다 0으로 만들기 (GT 포함)\n",
    "def option3(student_logit, teacher_logit, T, K):\n",
    "    new_teacher_logit = teacher_logit + torch.abs(torch.min(teacher_logit, dim=1).values.reshape(-1, 1))\n",
    "    new_teacher_logit = new_teacher_logit / 2\n",
    "    bar = torch.sort(new_teacher_logit, descending=True).values[:, K-1].reshape(-1, 1).repeat(1, teacher_logit.shape[1])\n",
    "    new_teacher_logit = torch.where(bar <= new_teacher_logit, new_teacher_logit, torch.zeros(1))\n",
    "    soft_label = F.softmax(new_teacher_logit / T, dim=1)\n",
    "    soft_prediction = F.log_softmax(student_logit / T, dim=1)\n",
    "    return F.kl_div(soft_prediction, soft_label)\n",
    "\n",
    "\n",
    "def FinalLoss_option1(teacher_logit, student_logit, labels, T, T1, T2, alpha, K):\n",
    "    return (1. - alpha) * F.cross_entropy(student_logit, labels) \\\n",
    "           + (alpha * T1 * T2) * option1(student_logit, teacher_logit, T, T1, T2, K)\n",
    "    \n",
    "    \n",
    "def FinalLoss_option2(teacher_logit, student_logit, labels, T, T1, T2, alpha, K):\n",
    "    return (1. - alpha) * F.cross_entropy(student_logit, labels) \\\n",
    "           + (alpha * T1 * T2) * option2(student_logit, teacher_logit, labels, T, T1, T2, K)\n",
    "    \n",
    "    \n",
    "def FinalLoss_option3(teacher_logit, student_logit, labels, T, alpha, K):\n",
    "    return (1. - alpha) * F.cross_entropy(student_logit, labels) \\\n",
    "           + (alpha * T * T) * option3(student_logit, teacher_logit, T, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "533ed177-aecb-4e32-a80e-4b1d191bb9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3638)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# option1(student_logit, teacher_logit, 2, 10, 20, 3)\n",
    "option2(student_logit, teacher_logit, labels, 2, 10, 20, 3)\n",
    "# option3(student_logit, teacher_logit, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ade74c-b486-4b2e-ae8d-5aee8518c22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177102d7-547f-4019-b663-9140f7750aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def option1_plt(student_logit, teacher_logit, T1, T2, K):\n",
    "    print(f'teacher_logit:\\n{teacher_logit}')\n",
    "    new_teacher_logit = teacher_logit + torch.abs(torch.min(teacher_logit, dim=1).values.reshape(-1,1))\n",
    "    print(f'new_teacher_logit:\\n{new_teacher_logit}')\n",
    "    bar = torch.sort(new_teacher_logit, descending=True).values[:, K-1].reshape(-1, 1).repeat(1, teacher_logit.shape[1])\n",
    "    print(f'bar:\\n{bar}')\n",
    "    top = torch.where(bar <= new_teacher_logit, new_teacher_logit, torch.zeros(1))\n",
    "    bot = torch.where(bar > new_teacher_logit, new_teacher_logit, torch.zeros(1))\n",
    "    print(f'top:\\n{top}')\n",
    "    print(f'bot:\\n{bot}')\n",
    "    print(f'top / T1:\\n{top / T1}')\n",
    "    print(f'bot / T2:\\n{bot / T2}')\n",
    "    print(f'final:\\n{(top / T1) + (bot / T2)}')\n",
    "    original = F.softmax(teacher_logit / T2, dim=1)\n",
    "    modified = F.softmax((top / T1) + (bot / T2), dim=1)\n",
    "    \n",
    "    for i in range(3):\n",
    "        plt.bar(range(6), original[i] * 100)\n",
    "        plt.ylim(ymax = 100)\n",
    "        plt.show()\n",
    "\n",
    "        plt.bar(range(6), modified[i] * 100)\n",
    "        plt.ylim(ymax = 100)\n",
    "        plt.show()\n",
    "\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
