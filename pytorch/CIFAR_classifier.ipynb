{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a5150e0-c9c2-4822-a6d9-1eaacbedd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5be31cc-2124-420e-92ce-c8bcf1cdd531",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((64, 64)),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "cifarset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "trainset, valid_set = random_split(cifarset, [40000, 10000])\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "testset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae655466-c25e-43be-8750-506420640473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (aap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 5)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(128, 128, 3)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.aap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.aap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5db85ed7-2799-497a-9b89-024688d5d5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "# scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac085d97-ada8-400b-9837-5fa24e653ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history, train_acc_history = [], []\n",
    "valid_loss_history, valid_acc_history = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0178c034-1502-48d5-8edc-db38a1347e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 || tl: 2.257, vl: 2.162 | ta: 13.845, va: 17.220\n",
      "epoch: 2 || tl: 2.118, vl: 2.020 | ta: 18.510, va: 20.240\n",
      "epoch: 3 || tl: 2.022, vl: 2.008 | ta: 21.805, va: 23.050\n",
      "epoch: 4 || tl: 1.952, vl: 1.982 | ta: 24.347, va: 25.300\n",
      "epoch: 5 || tl: 1.901, vl: 1.833 | ta: 26.500, va: 27.780\n",
      "epoch: 6 || tl: 1.867, vl: 1.893 | ta: 28.380, va: 28.790\n",
      "epoch: 7 || tl: 1.836, vl: 1.795 | ta: 29.565, va: 30.950\n",
      "epoch: 8 || tl: 1.816, vl: 1.801 | ta: 30.447, va: 30.760\n",
      "epoch: 9 || tl: 1.802, vl: 1.794 | ta: 31.102, va: 31.710\n",
      "epoch: 10 || tl: 1.779, vl: 1.754 | ta: 31.920, va: 33.050\n",
      "epoch: 11 || tl: 1.760, vl: 1.743 | ta: 32.947, va: 32.920\n",
      "epoch: 12 || tl: 1.751, vl: 1.803 | ta: 33.202, va: 34.150\n",
      "epoch: 13 || tl: 1.741, vl: 1.700 | ta: 33.590, va: 34.820\n",
      "epoch: 14 || tl: 1.726, vl: 1.762 | ta: 34.685, va: 35.260\n",
      "epoch: 15 || tl: 1.715, vl: 1.685 | ta: 35.117, va: 34.660\n",
      "epoch: 16 || tl: 1.702, vl: 1.697 | ta: 35.767, va: 36.070\n",
      "epoch: 17 || tl: 1.684, vl: 1.608 | ta: 36.240, va: 36.390\n",
      "epoch: 18 || tl: 1.674, vl: 1.629 | ta: 36.705, va: 37.100\n",
      "epoch: 19 || tl: 1.659, vl: 1.594 | ta: 37.557, va: 37.700\n",
      "epoch: 20 || tl: 1.647, vl: 1.645 | ta: 38.212, va: 38.090\n",
      "epoch: 21 || tl: 1.638, vl: 1.582 | ta: 38.595, va: 38.150\n",
      "epoch: 22 || tl: 1.627, vl: 1.530 | ta: 39.140, va: 38.270\n",
      "epoch: 23 || tl: 1.618, vl: 1.711 | ta: 39.255, va: 37.020\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5906/3227666511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtrain_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):   # 데이터셋을 수차례 반복합니다.\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "    \n",
    "    train_samples = 0\n",
    "    valid_samples = 0\n",
    "    \n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 변화도(Gradient) 매개변수를 0으로 만들고\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화를 한 후\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_loss += loss.item()\n",
    "        train_acc += torch.sum(preds == labels.data)\n",
    "        train_samples += len(inputs)\n",
    "    \n",
    "    else:\n",
    "        # 훈련팔 필요가 없으므로 메모리 절약\n",
    "        with torch.no_grad():\n",
    "            for valid_input, valid_label in valid_loader:\n",
    "                valid_input, valid_label = valid_input.to(device), valid_label.to(device)\n",
    "                valid_outputs = net(valid_input)\n",
    "                valid_loss = criterion(valid_outputs, valid_label)\n",
    "\n",
    "                _, valid_preds = torch.max(valid_outputs, 1)\n",
    "                valid_loss += valid_loss.item()\n",
    "                valid_acc += torch.sum(valid_preds == valid_label.data)\n",
    "                valid_samples += len(valid_input)\n",
    "                \n",
    "    epoch_loss = train_loss / len(trainloader)\n",
    "    epoch_acc = train_acc.float() / train_samples * 100\n",
    "    train_loss_history.append(epoch_loss)\n",
    "    train_acc_history.append(epoch_acc)\n",
    "\n",
    "    valid_epoch_loss = valid_loss * 10 / len(valid_loader)\n",
    "    valid_epoch_acc = valid_acc.float() / valid_samples * 100\n",
    "    valid_loss_history.append(valid_epoch_loss)\n",
    "    valid_acc_history.append(valid_epoch_acc)\n",
    "\n",
    "#     if (epoch + 1) % 5 == 0:\n",
    "    print(f\"epoch: {epoch + 1} || tl: {epoch_loss:.3f}, vl: {valid_epoch_loss:.3f} | ta: {epoch_acc:.3f}, va: {valid_epoch_acc:.3f}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2fe64-11e2-4373-b227-8cba4cbf7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# 학습 중이 아니므로, 출력에 대한 변화도를 계산할 필요가 없습니다\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # 신경망에 이미지를 통과시켜 출력을 계산합니다\n",
    "        outputs = net(images)\n",
    "        # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택하겠습니다\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039879d6-f3f6-4a9a-9e51-bfbcbc990692",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 변화도는 여전히 필요하지 않습니다\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # 각 분류별로 올바른 예측 수를 모읍니다\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# 각 분류별 정확도(accuracy)를 출력합니다\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d033b0-cb6e-42f5-92f9-c04e4a866ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "# plt.subplot(1, 2, 1)  \n",
    "# plt.title(\"Training and Validation Loss\")\n",
    "# plt.plot(valid_loss_history,label=\"val\")\n",
    "# plt.plot(train_loss_history,label=\"train\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2) \n",
    "plt.title(\"Training and Validation Acc\")\n",
    "plt.plot(valid_acc_history,label=\"val\")\n",
    "plt.plot(train_acc_history,label=\"train\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac4e98-49e1-4ec0-99b8-11c3f34ac915",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# net = Net()\n",
    "# net.load_state_dict(torch.load(PATH))\n",
    "# net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca06f4-838b-4397-8dab-de821ad62bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
